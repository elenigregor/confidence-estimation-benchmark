{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e9a32bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from ibm_watson import AssistantV2\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "from snips_nlu import SnipsNLUEngine\n",
    "from snips_nlu.default_configs import CONFIG_EN\n",
    "\n",
    "from numpy import exp\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d64cda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constants\n",
    "VERSION = 8\n",
    "NUM_SPLITS = 10\n",
    "\n",
    "# lists\n",
    "NLU_NAMES = ['watson', 'luis', 'snips']\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90908a1",
   "metadata": {},
   "source": [
    "## Train/ load NLU model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e46c75",
   "metadata": {},
   "source": [
    "### Snips.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "351e3eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(filename):\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e51bae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_snips(train_file):\n",
    "    train_dataset = read_json_file(train_file)\n",
    "    nlu_engine = SnipsNLUEngine(config=CONFIG_EN)\n",
    "    nlu_engine.fit(train_dataset)\n",
    "    return nlu_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb22e66",
   "metadata": {},
   "source": [
    "### Watson Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11806163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documentation: https://cloud.ibm.com/apidocs/assistant/assistant-v2?code=python\n",
    "authenticator = IAMAuthenticator(os.getenv(\"IBM_ASSISTANT_API_KEY\"))\n",
    "assistant = AssistantV2(\n",
    "    version='2022-02-02',\n",
    "    authenticator = authenticator\n",
    ")\n",
    "assistant.set_service_url(os.getenv(\"IBM_WATSON_REGION\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80053751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assistant_id(split_num):\n",
    "    split_num = str(split_num)\n",
    "    return 'IBM_SPLIT_' + split_num + '_ASSISTANT_ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e15247",
   "metadata": {},
   "source": [
    "### LUIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cfb4758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_app_id(split_num):\n",
    "    split_num = str(split_num)\n",
    "    return 'LUIS_SPLIT_' + split_num + '_APP_ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb018368",
   "metadata": {},
   "source": [
    "## Test NLU (Watson, LUIS and Snips.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ba3f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(nlu_name, split_num, version=VERSION):\n",
    "    # paths\n",
    "    train_file = '../datasets/' + nlu_name + '/v' + str(version) + '/' + nlu_name +'_split_' + str(split_num) + '_train_v' + str(version) + '.json' # snips only\n",
    "    test_file = '../datasets/' + nlu_name + '/v' + str(version) + '/' + nlu_name + '_split_' + str(split_num) + '_test_v' + str(version) + '.csv'\n",
    "    output_file = '../results/' + nlu_name + '/v' + str(version) + '/' + nlu_name + '_split_' + str(split_num) + '_results_v' + str(version) + '.json'\n",
    "    return train_file, test_file, output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9bea889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_keys(json_res, nlu='snips'):\n",
    "    for rank in json_res['intent_ranking']:\n",
    "        if nlu=='snips':\n",
    "            rank['name'] = rank.pop('intentName')\n",
    "            rank['confidence'] = rank.pop('probability')\n",
    "        elif nlu=='watson':\n",
    "            rank['name'] = rank.pop('intent')\n",
    "        else:\n",
    "            pass\n",
    "    return json_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "608220a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_is_correct(json_res):\n",
    "    if json_res['intent_ranking'][0]['name'] == intent:\n",
    "        json_res['is_correct'] = True\n",
    "    else:\n",
    "        json_res['is_correct'] = False\n",
    "    return json_res   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f308028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nlu_response(utterance, assistant=None, nlu_engine=None, nlu='snips', split_num=1):\n",
    "    if nlu=='watson':\n",
    "        ibm_assistant_id = get_assistant_id(split_num)\n",
    "        response = assistant.message_stateless(\n",
    "            assistant_id=os.getenv(ibm_assistant_id),\n",
    "                input={\n",
    "                    'message_type': 'text',\n",
    "                    'text': utterance,\n",
    "                    'options' : {'alternate_intents': True}\n",
    "                }\n",
    "            ).get_result()\n",
    "    elif nlu=='snips':\n",
    "        response = nlu_engine.get_intents(utterance)\n",
    "    elif nlu=='luis':\n",
    "        luis_app_id = get_app_id(split_num)\n",
    "        appId = os.getenv(luis_app_id)\n",
    "        prediction_key = os.getenv(\"LUIS_PREDICTION_SUBSCRIPTION_KEY\")\n",
    "        prediction_endpoint = os.getenv(\"LUIS_PREDICTION_ENDPOINT\")\n",
    "        # The URL parameters to use in this REST call.\n",
    "        headers = {}\n",
    "        params ={\n",
    "            'query': utterance,\n",
    "            'timezoneOffset': '0',\n",
    "            'verbose': 'true',\n",
    "            'show-all-intents': 'true',\n",
    "            'spellCheck': 'false',\n",
    "            'staging': 'false',\n",
    "            'subscription-key': prediction_key\n",
    "        }\n",
    "\n",
    "        # Make the REST call.\n",
    "        response = requests.get(f'{prediction_endpoint}luis/prediction/v3.0/apps/{appId}/slots/production/predict', headers=headers, params=params)\n",
    "        response = response.json()\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5b22316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sleep_if_luis(i, nlu='luis'): \n",
    "    \"\"\"\n",
    "    This function is used to keep a rate of 5TC per second when running LUIS\n",
    "    \"\"\"\n",
    "    if i % 5 == 4 and nlu=='luis': # not 0 because indecies start at 0\n",
    "        time.sleep(1.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5515b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_path):\n",
    "    file = open(file_path)\n",
    "    reader = csv.reader(file, delimiter=',')\n",
    "    return reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91f27da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(output_file, results, nlu_name, version):\n",
    "    if not path.exists('../results/' + nlu_name):\n",
    "                os.mkdir('../results/' + nlu_name)\n",
    "    if not path.exists('../results/' + nlu_name + '/v' + str(version)):\n",
    "                os.mkdir('../results/' + nlu_name + '/v' + str(version))\n",
    "    with open(output_file, 'w') as f:\n",
    "                json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3caa867",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nlu_name in NLU_NAMES:\n",
    "    for split in range(NUM_SPLITS):\n",
    "        split_num = split + 1\n",
    "        results = []\n",
    "        train_file, test_file, output_file = get_params(nlu_name, split_num, version=VERSION)\n",
    "        reader = read_csv(test_file)\n",
    "        \n",
    "        if nlu_name=='snips':\n",
    "            nlu_engine = train_snips(train_file)\n",
    "            \n",
    "        for i, row in enumerate(reader):\n",
    "            intent = row[1]\n",
    "            utterance = row[0]\n",
    "\n",
    "            if i==0 or utterance=='': # skip header and empty utterances\n",
    "                continue \n",
    "            sleep_if_luis(i, nlu=nlu_name)\n",
    "\n",
    "            # pass a user utterance to the NLU and get response\n",
    "            if nlu_name == 'watson':\n",
    "                response = get_nlu_response(utterance, assistant=assistant, nlu=nlu_name, split_num=split_num)\n",
    "                intent_ranking = response['output']['intents']\n",
    "                \n",
    "            elif nlu_name == 'snips':\n",
    "                intent_ranking = get_nlu_response(utterance, nlu_engine=nlu_engine, nlu=nlu_name, split_num=split_num)\n",
    "                intent_ranking = [r for r in intent_ranking if r['intentName'] != None]\n",
    "                \n",
    "            elif nlu_name == 'luis':\n",
    "                response = get_nlu_response(utterance, nlu=nlu_name, split_num=split_num)\n",
    "                try:\n",
    "                    intent_ranking = response['prediction']['intents']\n",
    "                    intent_ranking = [{'name' : n, 'confidence': s['score']} for n,s in intent_ranking.items()]\n",
    "                    intent_ranking = [r for r in intent_ranking if r['name'] != None and r['name'] != 'None']\n",
    "                except:\n",
    "                    print(response)\n",
    "                    print(\"Trying to recover ...\")\n",
    "                    time.sleep(1)\n",
    "                    response = get_nlu_response(utterance, nlu=nlu_name, split_num=split_num)\n",
    "                    try:\n",
    "                        intent_ranking = response['prediction']['intents']\n",
    "                        intent_ranking = [{'name' : n, 'confidence': s['score']} for n,s in intent_ranking.items()]\n",
    "                    except:\n",
    "                        print(\"Failed to recover. Adding an empty list to intent_ranking\")\n",
    "                        intent_ranking = []\n",
    "\n",
    "                        \n",
    "            # resturctre results\n",
    "            json_res = { 'text': utterance,\n",
    "                         'correct_intent' : intent,\n",
    "                         'intent_ranking' : intent_ranking\n",
    "                        }\n",
    "\n",
    "            json_res = unify_keys(json_res, nlu=nlu_name)\n",
    "            json_res = add_is_correct(json_res)\n",
    "\n",
    "            results.append(json_res)\n",
    "           \n",
    "        write_results(output_file, results, nlu_name, VERSION)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:snips_env]",
   "language": "python",
   "name": "conda-env-snips_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
